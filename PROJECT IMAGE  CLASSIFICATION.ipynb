{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CIFAR-10 Dataset: 171MB [03:00, 945kB/s]                                       \n"
     ]
    }
   ],
   "source": [
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve('https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "        'cifar-10-python.tar.gz',pbar.hook)\n",
    "    \n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().magic('matplotlib inline')\n",
    "get_ipython().magic(\"config InlineBackend.figure_format = 'retina'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_label_names():\n",
    "\"\"\"\n",
    "Load the label names from file\n",
    "\"\"\"\n",
    "return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cfar10_batch(cifar10_dataset_folder_path, batch_id):\n",
    "\"\"\"\n",
    "Load a batch of the dataset\n",
    "\"\"\"\n",
    "with open(cifar10_dataset_folder_path + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
    "batch = pickle.load(file, encoding='latin1')\n",
    "features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "labels = batch['labels']\n",
    "return features, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-2-ede14fb5c293>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-ede14fb5c293>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    \"\"\"\u001b[0m\n\u001b[1;37m       \n^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def display_stats(cifar10_dataset_folder_path, batch_id, sample_id):\n",
    "\"\"\"\n",
    "Display Stats of the the dataset\n",
    "\"\"\"\n",
    "    batch_ids = list(range(1, 6))\n",
    "\n",
    "if batch_id not in batch_ids:\n",
    "print('Batch Id out of Range. Possible Batch Ids: {}'.format(batch_ids))\n",
    "return None\n",
    "\n",
    "features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_id)\n",
    "\n",
    "if not (0 <= sample_id < len(features)):\n",
    "print('{} samples in batch {}. {} is out of range.'.format(len(features), batch_id, sample_id))\n",
    "return None\n",
    "\n",
    "print('\\nStats of batch {}:'.format(batch_id))\n",
    "print('Samples: {}'.format(len(features)))\n",
    "print('Label Counts: {}'.format(dict(zip(*np.unique(labels, return_counts=True)))))\n",
    "print('First 20 Labels: {}'.format(labels[:20]))\n",
    "sample_image = features[sample_id]\n",
    "sample_label = labels[sample_id]\n",
    "label_names = _load_label_names()\n",
    "print('\\nExample of Image {}:'.format(sample_id))\n",
    "print('Image - Min Value: {} Max Value: {}'.format(sample_image.min(), sample_image.max()))\n",
    "print('Image - Shape: {}'.format(sample_image.shape))\n",
    "print('Label - Label Id: {} Name: {}'.format(sample_label, label_names[sample_label]))\n",
    "plt.axis('off')\n",
    "plt.imshow(sample_image)\n",
    "\n",
    "def _preprocess_and_save(normalize, one_hot_encode, features, labels, filename):\n",
    "\"\"\"\n",
    "Preprocess data and save it to file\n",
    "\"\"\"\n",
    "features = normalize(features)\n",
    "labels = one_hot_encode(labels)\n",
    "pickle.dump((features, labels), open(filename, 'wb'))\n",
    "\n",
    "def preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode):\n",
    "\"\"\"\n",
    "Preprocess Training and Validation Data\n",
    "\"\"\"\n",
    "n_batches = 5\n",
    "valid_features = []\n",
    "valid_labels = []\n",
    "for batch_i in range(1, n_batches + 1):\n",
    "features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_i)\n",
    "validation_count = int(len(features) * 0.1)\n",
    "# Prprocess and save a batch of training\n",
    "data _preprocess_and_save(\n",
    "normalize,\n",
    "one_hot_encode, features[:-\n",
    "validation_count], labels[:-\n",
    "validation_count], 'preprocess_batch_'\n",
    "+ str(batch_i) + '.p')\n",
    "# Use a portion of training batch for validation\n",
    "valid_features.extend(features[-validation_count:])\n",
    "valid_labels.extend(labels[-validation_count:])\n",
    "# Preprocess and Save all validation data\n",
    "_preprocess_and_save(\n",
    "                    normalize,\n",
    "                    one_hot_encode,\n",
    "                    np.array(valid_features),\n",
    "                    np.array(valid_labels),\n",
    "                    'preprocess_validation.p')\n",
    "with open(cifar10_dataset_folder_path + '/test_batch', mode='rb') as file:\n",
    "batch = pickle.load(file, encoding='latin1')\n",
    "# load the training data\n",
    "test_features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
    "test_labels = batch['labels']\n",
    "# Preprocess and Save all training\n",
    "data _preprocess_and_save(normalize,one_hot_encode,\n",
    "                        np.array(test_features),\n",
    "                        np.array(test_labels),\n",
    "                        'preprocess_training.p')\n",
    "\n",
    "def batch_features_labels(features, labels, batch_size):\n",
    "\"\"\"\n",
    "Split features and labels into batches\n",
    "\"\"\"\n",
    "for start in range(0, len(features), batch_size):\n",
    "end = min(start + batch_size, len(features))\n",
    "yield features[start:end], labels[start:end]\n",
    "\n",
    "def load_preprocess_training_batch(batch_id, batch_size):\n",
    "\"\"\"\n",
    "Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "\"\"\"\n",
    "filename = 'preprocess_batch_' + str(batch_id) + '.p'\n",
    "features, labels = pickle.load(open(filename, mode='rb'))\n",
    "# Return the training data in batches of size <batch_size> or\n",
    "less return batch_features_labels(features, labels, batch_size)\n",
    "\n",
    "def display_image_predictions(features, labels, predictions):\n",
    "    n_classes = 10\n",
    "\n",
    "    label_names = _load_label_names()\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    label_binarizer.fit(range(n_classes))\n",
    "    label_ids = label_binarizer.inverse_transform(np.array(labels))\n",
    "\n",
    "fig, axies = plt.subplots(nrows=4, ncols=2)\n",
    "fig.tight_layout()\n",
    "fig.suptitle('Softmax Predictions', fontsize=20, y=1.1)\n",
    "                n_predictions = 3\n",
    "                margin = 0.05\n",
    "                ind = np.arange(n_predictions)\n",
    "                width = (1. - 2. * margin) / n_predictions\n",
    "\n",
    "for image_i, (feature, label_id, pred_indicies, pred_values) in enumerate(zip(features, label_ids, predictions.i\n",
    "                ndices, predictions.values)):\n",
    "pred_names = [label_names[pred_i] for pred_i in\n",
    "pred_indicies] correct_name = label_names[label_id]\n",
    "axies[image_i][0].imshow(feature*255)\n",
    "axies[image_i][0].set_title(correct_name)\n",
    "axies[image_i][0].set_axis_off()\n",
    "axies[image_i][1].barh(ind + margin, pred_values[::-1], width)\n",
    "axies[image_i][1].set_yticks(ind + margin)\n",
    "axies[image_i][1].set_yticklabels(pred_names[::-1])\n",
    "axies[image_i][1].set_xticks([0, 0.5, 1.0])\n",
    "-----------------------------------------------\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "# Explore the\n",
    "dataset batch_id = 3\n",
    "sample_id = 5\n",
    "display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
